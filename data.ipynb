{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mvm9KLxAiYqi"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uTKPzu28dHvF"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade anytree==2.8.0 google-cloud-firestore==2.3.4 google-cloud-storage==2.1.0 lxml==4.7.1 openai==0.13.0 pylatexenc==2.10\n",
        "!pip install --upgrade --use-deprecated=legacy-resolver selenium==4.1.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QNBY5xlIc3F7"
      },
      "outputs": [],
      "source": [
        "import anytree\n",
        "from datetime import datetime\n",
        "from google.cloud import firestore\n",
        "from google.cloud import storage\n",
        "import json\n",
        "import lxml.html\n",
        "import openai\n",
        "from pylatexenc import latexwalker\n",
        "from pylatexenc.latexwalker import LatexEnvironmentNode\n",
        "from pylatexenc.latexwalker import LatexGroupNode\n",
        "from pylatexenc.latexwalker import LatexMacroNode\n",
        "from pylatexenc.latexwalker import LatexWalker\n",
        "from pylatexenc import latex2text\n",
        "from pylatexenc.latex2text import EnvironmentTextSpec\n",
        "from pylatexenc.latex2text import fmt_matrix_environment_node\n",
        "from pylatexenc.latex2text import LatexNodes2Text\n",
        "from pylatexenc.latex2text import MacroTextSpec\n",
        "from pylatexenc.latex2text import SpecialsTextSpec\n",
        "from pylatexenc.macrospec import EnvironmentSpec\n",
        "from pylatexenc.macrospec import MacroSpec\n",
        "from pylatexenc.macrospec import MacroStandardArgsParser\n",
        "from pylatexenc.macrospec import SpecialsSpec\n",
        "import random\n",
        "import re\n",
        "import requests\n",
        "from selenium import webdriver\n",
        "import subprocess\n",
        "import sys"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oF7bK-Wc1mJh"
      },
      "outputs": [],
      "source": [
        "!apt-get -y update && apt-get install -y chromium-chromedriver fonts-noto"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bRYFbF9aM9TT"
      },
      "outputs": [],
      "source": [
        "%%writefile /etc/fonts/local.conf\n",
        "<?xml version=\"1.0\"?>\n",
        "<!DOCTYPE fontconfig SYSTEM \"fonts.dtd\">\n",
        "<fontconfig>\n",
        "\t<match target=\"pattern\">\n",
        "\t\t<test qual=\"any\" name=\"family\">\n",
        "\t\t\t<string>serif</string>\n",
        "\t\t</test>\n",
        "\t\t<edit name=\"family\" mode=\"assign\" binding=\"same\">\n",
        "\t\t\t<string>Noto Serif</string>\n",
        "\t\t</edit>\n",
        "\t</match>\n",
        "</fontconfig>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "peAviQuRco2y"
      },
      "outputs": [],
      "source": [
        "!fc-cache -fv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-F6becSrvS9Y"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/maxbbraun/wittgenstein.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XyTY9jt88yOg"
      },
      "outputs": [],
      "source": [
        "openai_api_key = ''  # @param {type:\"string\"}\n",
        "openai.organization = ''  # @param {type:\"string\"}\n",
        "\n",
        "%env OPENAI_API_KEY=$openai_api_key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tOjBRFQHns7x"
      },
      "outputs": [],
      "source": [
        "google_cloud_project = ''  # @param {type:\"string\"}\n",
        "google_application_credentials = ''  # @param {type:\"string\"}\n",
        "\n",
        "%env GOOGLE_APPLICATION_CREDENTIALS=$google_application_credentials\n",
        "!gcloud config set project $google_cloud_project"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bKGZ7PlrxGIx"
      },
      "source": [
        "# Data Preparation\n",
        "\n",
        "Source: [Project Gutenberg](https://www.gutenberg.org/ebooks/5740), with [corrections](https://github.com/maxbbraun/wittgenstein/commits/main/tractatus.tex)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "h3w5NI-zjyHC"
      },
      "outputs": [],
      "source": [
        "# Load the (corrected) LaTeX version of the Tractatus into memory.\n",
        "with open('wittgenstein/tractatus.tex') as f:\n",
        "    tractatus_latex = f.read()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "07YK6FQpcjYD"
      },
      "outputs": [],
      "source": [
        "# Define parsing rules for turning LaTeX into Unicode text with minimal HTML.\n",
        "def init_pylatexenc(translate_to_english, include_footnotes=False):\n",
        "    walker_context = latexwalker.get_default_latex_context_db()\n",
        "    walker_context.add_context_category(\n",
        "        'tractatus',\n",
        "        prepend=True,\n",
        "        macros=[\n",
        "            MacroSpec('binom', '{{'),\n",
        "            MacroSpec('BookTitle', '{'),\n",
        "            MacroSpec('discretionary', '{{{'),\n",
        "            MacroSpec('DPtypo', '{{'),\n",
        "            MacroSpec('emph', '{'),\n",
        "            MacroSpec('Emph', '{'),\n",
        "            MacroSpec('EmphPart', '{'),\n",
        "            MacroSpec('enlargethispage', '{'),\n",
        "            MacroSpec('glq', '{'),\n",
        "            MacroSpec('glqq', '{'),\n",
        "            MacroSpec('grq', '{'),\n",
        "            MacroSpec('grqq', '{'),\n",
        "            MacroSpec('hspace', '{'),\n",
        "            MacroSpec('Illustration', '[{'),\n",
        "            MacroSpec('mbox', '{'),\n",
        "            MacroSpec('Not', '{'),\n",
        "            MacroSpec('overline', '{'),\n",
        "            MacroSpec('phantom', '{'),\n",
        "            MacroSpec('PropERef', '{'),\n",
        "            MacroSpec('PropGRef', '{'),\n",
        "            MacroSpec('PropositionE', '{{'),\n",
        "            MacroSpec('PropositionG', '{{'),\n",
        "            MacroSpec('raisebox', '{[[{'),\n",
        "            MacroSpec('smash', '[[{'),\n",
        "            MacroSpec('text', '{'),\n",
        "            MacroSpec('textit', '{'),\n",
        "            MacroSpec('vspace', '{')],\n",
        "        environments=[\n",
        "            EnvironmentSpec('array', '[{', is_math_mode=True),\n",
        "            EnvironmentSpec('split', '', is_math_mode=True),\n",
        "            EnvironmentSpec('tabular', '[{')],\n",
        "        specials=[\n",
        "            SpecialsSpec('`'),\n",
        "            SpecialsSpec(\"'\"),\n",
        "            SpecialsSpec('``'),\n",
        "            SpecialsSpec(\"''\"),\n",
        "            SpecialsSpec('&'),\n",
        "            SpecialsSpec('^', args_parser=MacroStandardArgsParser('{')),\n",
        "            SpecialsSpec('_', args_parser=MacroStandardArgsParser('{'))])\n",
        "    latex_walker = LatexWalker(tractatus_latex, latex_context=walker_context)\n",
        "\n",
        "    if translate_to_english:\n",
        "        footnote_pattern = r' (Footnote: %(2)s)' if include_footnotes else ''\n",
        "        binomial_pattern = r'(%(1)s choose %(2)s)'\n",
        "        single_open_quote = '‘'\n",
        "        single_close_quote = '’'\n",
        "        double_open_quote = '“'\n",
        "        double_close_quote = '”'\n",
        "        illustration_placeholder = '[Figure]'\n",
        "    else:\n",
        "        footnote_pattern = r' (Fußnote: %(2)s)' if include_footnotes else ''\n",
        "        binomial_pattern = r'(%(1)s über %(2)s)'\n",
        "        single_open_quote = '‚'\n",
        "        single_close_quote = '‘'\n",
        "        double_open_quote = '„'\n",
        "        double_close_quote = '“'\n",
        "        illustration_placeholder = '[Abbildung]'\n",
        "\n",
        "    nodes2text_context = latex2text.get_default_latex_context_db()\n",
        "    nodes2text_context.add_context_category(\n",
        "        'tractatus',\n",
        "        prepend=True,\n",
        "        macros=[\n",
        "            MacroTextSpec('-', discard=True),\n",
        "            MacroTextSpec('AllowBreak', discard=True),\n",
        "            MacroTextSpec('BarOp', simplify_repl=' | '),\n",
        "            MacroTextSpec('binom', simplify_repl=binomial_pattern),\n",
        "            MacroTextSpec('BookTitle', simplify_repl=r'%s'),\n",
        "            MacroTextSpec('dasHeiszt', simplify_repl='d. h.'),\n",
        "            MacroTextSpec('discretionary', simplify_repl=r'%(3)s'),\n",
        "            MacroTextSpec('DittoInWords', simplify_repl='„'),\n",
        "            MacroTextSpec('DittoInWorten', simplify_repl='„'),\n",
        "            MacroTextSpec('DotOp', simplify_repl=' . '),\n",
        "            MacroTextSpec('DPtypo', simplify_repl=r'%(2)s'),\n",
        "            MacroTextSpec('emph', simplify_repl=r'<em>%s</em>'),\n",
        "            MacroTextSpec('Emph', simplify_repl=r'<em>%s</em>'),\n",
        "            MacroTextSpec('EmphPart', simplify_repl=r'<em>%s</em>'),\n",
        "            MacroTextSpec('False', simplify_repl='F'),\n",
        "            MacroTextSpec('enlargethispage', discard=True),\n",
        "            MacroTextSpec('exempliGratia', simplify_repl='e.g.'),\n",
        "            MacroTextSpec('ExempliGratia', simplify_repl='E.g.'),\n",
        "            MacroTextSpec('fivedots', simplify_repl='.....'),\n",
        "            MacroTextSpec('footnote', simplify_repl=footnote_pattern),\n",
        "            MacroTextSpec('fourdots', simplify_repl='....'),\n",
        "            MacroTextSpec('glq', simplify_repl=single_open_quote),\n",
        "            MacroTextSpec('glqq', simplify_repl=double_open_quote),\n",
        "            MacroTextSpec('grq', simplify_repl=single_close_quote),\n",
        "            MacroTextSpec('grqq', simplify_repl=double_close_quote),\n",
        "            MacroTextSpec('hline', simplify_repl='; '),\n",
        "            MacroTextSpec('hspace', discard=True),\n",
        "            MacroTextSpec('idEst', simplify_repl='i.e.'),\n",
        "            MacroTextSpec('IdEst', simplify_repl='I.e.'),\n",
        "            MacroTextSpec('Illustration',\n",
        "                          simplify_repl=illustration_placeholder),\n",
        "            MacroTextSpec('Implies', simplify_repl='⊃'),\n",
        "            MacroTextSpec('lor', simplify_repl='v'),\n",
        "            MacroTextSpec('mbox', simplify_repl='%s'),\n",
        "            MacroTextSpec('Not', simplify_repl='~%s'),\n",
        "            MacroTextSpec('overline', simplify_repl='%s\\u0305'),\n",
        "            MacroTextSpec('phantom', discard=True),\n",
        "            MacroTextSpec('PropERef', simplify_repl=r'%s'),\n",
        "            MacroTextSpec('PropGRef', simplify_repl=r'%s'),\n",
        "            MacroTextSpec('raisebox', simplify_repl=r'%(4)s'),\n",
        "            MacroTextSpec('smash', simplify_repl=r'%(3)s'),\n",
        "            MacroTextSpec('stretchyspace', discard=True),\n",
        "            MacroTextSpec('text', simplify_repl=r'%s'),\n",
        "            MacroTextSpec('textit', simplify_repl=r'<i>%s<i>'),\n",
        "            MacroTextSpec('undAndere', simplify_repl='u. a.'),\n",
        "            MacroTextSpec('undSoFort', simplify_repl='u. s. f.'),\n",
        "            MacroTextSpec('UndSoWeiter', simplify_repl='U. s. w.'),\n",
        "            MacroTextSpec('verystretchyspace', discard=True),\n",
        "            MacroTextSpec('vspace', discard=True),\n",
        "            MacroTextSpec('Wahr', simplify_repl='W'),\n",
        "            MacroTextSpec('zumBeispiel', simplify_repl='z. B.'),\n",
        "            MacroTextSpec('ZumBeispiel', simplify_repl='Z. B.')],\n",
        "        environments=[\n",
        "            EnvironmentTextSpec('array',\n",
        "                                simplify_repl=fmt_matrix_environment_node),\n",
        "            EnvironmentTextSpec('split',\n",
        "                                simplify_repl=fmt_matrix_environment_node),\n",
        "            EnvironmentTextSpec('tabular',\n",
        "                                simplify_repl=fmt_matrix_environment_node)],\n",
        "        specials=[\n",
        "            SpecialsTextSpec('`', single_open_quote),\n",
        "            SpecialsTextSpec(\"'\", single_close_quote),\n",
        "            SpecialsTextSpec('``', double_open_quote),\n",
        "            SpecialsTextSpec(\"''\", double_close_quote),\n",
        "            SpecialsTextSpec('&', '|'),\n",
        "            SpecialsTextSpec('^', simplify_repl='<sup>%s</sup>'),\n",
        "            SpecialsTextSpec('_', simplify_repl='<sub>%s</sub>')])\n",
        "    nodes2text = LatexNodes2Text(latex_context=nodes2text_context,\n",
        "                                 math_mode='text',\n",
        "                                 keep_braced_groups=False)\n",
        "\n",
        "    return latex_walker, nodes2text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Shcznprpc-Ya"
      },
      "outputs": [],
      "source": [
        "# Find the propositions in the structured text.\n",
        "def gather_propositions(translate_to_english, nodes=None, latex_walker=None,\n",
        "                        nodes2text=None):\n",
        "    if not nodes:\n",
        "        latex_walker, nodes2text = init_pylatexenc(\n",
        "            translate_to_english=translate_to_english)\n",
        "        nodes, _, _ = latex_walker.get_latex_nodes()\n",
        "    assert latex_walker\n",
        "    assert nodes2text\n",
        "\n",
        "    # Pick the proposition macro based on the selected language.\n",
        "    if translate_to_english:\n",
        "        proposition_macro = 'PropositionE'\n",
        "    else:\n",
        "        proposition_macro = 'PropositionG'\n",
        "\n",
        "    # Walk the nodes tree recursively and extract all propositions.\n",
        "    propositions = []\n",
        "    for node in nodes:\n",
        "        if (node.isNodeType(LatexGroupNode) or\n",
        "            node.isNodeType(LatexEnvironmentNode)):\n",
        "            # Recurse into groups of nodes.\n",
        "            child_nodes = node.nodelist\n",
        "            if child_nodes:\n",
        "                child_propositions = gather_propositions(\n",
        "                    translate_to_english=translate_to_english, nodes=child_nodes,\n",
        "                    latex_walker=latex_walker, nodes2text=nodes2text)\n",
        "                propositions.extend(child_propositions)\n",
        "        elif (node.isNodeType(LatexMacroNode) and\n",
        "              node.macroname == proposition_macro):\n",
        "            # Expect the proposition's number and content as the node arguments.\n",
        "            proposition_nodes = node.nodeargd.argnlist\n",
        "            assert len(proposition_nodes) == 2\n",
        "            number_node = proposition_nodes[0]\n",
        "            content_node = proposition_nodes[1]\n",
        "\n",
        "            # Convert the number and content to text.\n",
        "            number = nodes2text.node_to_text(number_node)\n",
        "            content = nodes2text.node_to_text(content_node)\n",
        "\n",
        "            # Remove any repeated and trailing whitespace.\n",
        "            content = re.sub(r'\\s+', ' ', content).strip()\n",
        "\n",
        "            proposition = (number, content)\n",
        "            propositions.append(proposition)\n",
        "\n",
        "    return propositions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "EmDDjCmOoQAF"
      },
      "outputs": [],
      "source": [
        "# Extract the propositions for both languages.\n",
        "german_propositions = gather_propositions(translate_to_english=False)\n",
        "english_propositions = gather_propositions(translate_to_english=True)\n",
        "assert len(german_propositions) == len(english_propositions)\n",
        "propositions = list(zip(german_propositions, english_propositions))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XZVKk9tv3GGG"
      },
      "outputs": [],
      "source": [
        "# Put the propositions into a tree structure.\n",
        "propositions_tree = anytree.AnyNode(number='')\n",
        "for german_proposition, english_proposition in propositions:\n",
        "    number, german_content = german_proposition\n",
        "    english_number, english_content = english_proposition\n",
        "    assert number == english_number\n",
        "\n",
        "    # Determine the number of the parent.\n",
        "    parent_number = number[:-1]\n",
        "    while parent_number.endswith('0'):\n",
        "        parent_number = parent_number[:-1]\n",
        "    if parent_number.endswith('.'):\n",
        "        parent_number = parent_number[:-1]\n",
        "    def parent_number_filter(node):\n",
        "        return node.number == parent_number\n",
        "    parent_node = anytree.search.find(propositions_tree,\n",
        "                                      filter_=parent_number_filter)\n",
        "\n",
        "    # Create the new node and attach it to the parent.\n",
        "    anytree.AnyNode(number=number, parent=parent_node,\n",
        "                    german_content=german_content,\n",
        "                    english_content=english_content)\n",
        "\n",
        "print(anytree.RenderTree(propositions_tree))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZcL0AznClUoA"
      },
      "source": [
        "# Data Inspection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "pB942k2kCYdu"
      },
      "outputs": [],
      "source": [
        "def proposition_importance(proposition_number):\n",
        "    # The importance of the proposition, with 0 being the most important.\n",
        "    number_match = re.search(r'(\\d+)(\\.(\\d+))?', proposition_number)\n",
        "    importance = len(number_match.group(3) or '')\n",
        "\n",
        "    return importance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "V9oU3FTXNhHP"
      },
      "outputs": [],
      "source": [
        "def proposition_html(number, german_content, english_content):\n",
        "    html = ''\n",
        "\n",
        "    # Hide all but 0 importance propositions by default.\n",
        "    if proposition_importance(number) > 0:\n",
        "        html += '<tr class=\"expandable\" style=\"display: none;\">\\n'\n",
        "    else:\n",
        "        html += '<tr>\\n'\n",
        "\n",
        "    # See frontend/templates/index.html for CSS.\n",
        "    html += f'  <td class=\"english number mobile\">{number}</td>\\n'\n",
        "    html += f'  <td class=\"english proposition\">{english_content}</td>\\n'\n",
        "    html += f'  <td class=\"german number nomobile\" lang=\"de\">{number}</td>\\n'\n",
        "    html += f'  <td class=\"german proposition nomobile\" lang=\"de\">{german_content}</td>\\n'\n",
        "    html += '</tr>'\n",
        "\n",
        "    return html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5bTXYpaTXWsN"
      },
      "outputs": [],
      "source": [
        "importance_limit = 5  # @param {type:\"slider\", min:0, max:5, step:1}\n",
        "proposition_prefix = ''  # @param{type:\"string\"}\n",
        "as_html = True  # @param {type:\"boolean\"}\n",
        "reverse = True  # @param {type:\"boolean\"}\n",
        "\n",
        "if reverse:\n",
        "    ordered = reversed(propositions)\n",
        "else:\n",
        "    ordered = propositions\n",
        "\n",
        "for german_proposition, english_proposition in ordered:\n",
        "    number, german_content = german_proposition\n",
        "    english_number, english_content = english_proposition\n",
        "    assert number == english_number\n",
        "\n",
        "    if not number.startswith(proposition_prefix):\n",
        "        continue\n",
        "\n",
        "    importance = proposition_importance(number)\n",
        "    if importance > importance_limit:\n",
        "        continue\n",
        "\n",
        "    if as_html:\n",
        "        print(proposition_html(number, german_content, english_content))\n",
        "    else:\n",
        "        print(f'{number} {german_content}')\n",
        "        print(f'{number} {english_content}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6jbPIStXw_l8"
      },
      "source": [
        "# Training\n",
        "\n",
        "Documentation: [OpenAI](https://beta.openai.com/docs/guides/fine-tuning)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "RcYFHdyhd23H"
      },
      "outputs": [],
      "source": [
        "prompt_separator = ' ->'  # @param{type:\"string\"}\n",
        "language_separator = '==='  # @param{type:\"string\"}\n",
        "proposition_separator = '\\n'  # @param{type:\"string\"}\n",
        "stop_sequence = '###'  # @param{type:\"string\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "qWCDzP9YwfIm"
      },
      "outputs": [],
      "source": [
        "training_filename = f'tractatus-{int(datetime.now().timestamp())}.jsonl'\n",
        "\n",
        "with open(training_filename, 'w', encoding='utf-8') as training_file:\n",
        "    for node in anytree.PreOrderIter(propositions_tree,\n",
        "                                     filter_=lambda node: node.number):\n",
        "        prompt = node.number\n",
        "        completion = (f' {node.german_content}'\n",
        "                      f'{language_separator}'\n",
        "                      f'{node.english_content}')\n",
        "\n",
        "        prompt += prompt_separator\n",
        "        completion += stop_sequence\n",
        "\n",
        "        data = {\n",
        "            'prompt': prompt,\n",
        "            'completion': completion\n",
        "        }\n",
        "        json_line = f'{json.dumps(data, ensure_ascii=False)}\\n'\n",
        "        training_file.write(json_line)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7wjD6j14vTTQ"
      },
      "outputs": [],
      "source": [
        "!openai tools fine_tunes.prepare_data --file $training_filename"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yzsLBnAhv_ju"
      },
      "outputs": [],
      "source": [
        "model = 'davinci'  # @param [\"ada\", \"babbage\", \"curie\", \"davinci\"]\n",
        "batch_size = 1  # @param{type:\"integer\"}\n",
        "n_epochs = 4  # @param{type:\"integer\"}\n",
        "learning_rate_multiplier = 0.02  # @param{type:\"number\"}\n",
        "prompt_loss_weight = 0.1  # @param{type:\"number\"}\n",
        "\n",
        "!openai api fine_tunes.create --training_file $training_filename --model $model --batch_size $batch_size --n_epochs $n_epochs --learning_rate_multiplier $learning_rate_multiplier --prompt_loss_weight $prompt_loss_weight"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zA1SgdNoxOzf"
      },
      "source": [
        "# Inference\n",
        "\n",
        "Documentation: [OpenAI](https://beta.openai.com/docs/api-reference), [Firestore](https://firebase.google.com/docs/firestore), [Cloud Storage](https://cloud.google.com/storage/docs/reference/libraries)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "0lAeNjBMi5aa"
      },
      "outputs": [],
      "source": [
        "def complete(model, prompt, prompt_separator, num_completions, max_tokens,\n",
        "             top_p, stop_sequence, presence_penalty, frequency_penalty):\n",
        "    return openai.Completion.create(\n",
        "        model=model,\n",
        "        prompt=f'{prompt}{prompt_separator}',\n",
        "        n=num_completions,\n",
        "        max_tokens=max_tokens,\n",
        "        top_p=top_p,\n",
        "        stop=stop_sequence,\n",
        "        presence_penalty=presence_penalty,\n",
        "        frequency_penalty=frequency_penalty)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "k7oHA-aL_qg2"
      },
      "outputs": [],
      "source": [
        "openai.api_key = openai_api_key\n",
        "fine_tuned_model = ''  # @param {type:\"string\"}\n",
        "prompt = '8'  # @param {type:\"string\"}\n",
        "max_tokens = 1024  # @param {type:\"integer\"}\n",
        "top_p = 0.8  # @param {type:\"slider\", min:0, max:1, step:0.01}\n",
        "presence_penalty = 1  # @param {type:\"slider\", min:-2.0, max:2.0, step:0.1}\n",
        "frequency_penalty = 1  # @param {type:\"slider\", min:-2.0, max:2.0, step:0.1}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "Roe2rbd6rYxn"
      },
      "outputs": [],
      "source": [
        "# Any partial match, ignoring formatting, is considered plagiarism.\n",
        "def plagiarism(new_german, new_english, old_propositions):\n",
        "    new_german = lxml.html.fromstring(new_german).text_content()\n",
        "    new_english = lxml.html.fromstring(new_english).text_content()\n",
        "    for (_, old_german), (_, old_english) in old_propositions:\n",
        "        old_german = lxml.html.fromstring(old_german).text_content()\n",
        "        old_english = lxml.html.fromstring(old_english).text_content()\n",
        "        if new_german in old_german or new_english in old_english:\n",
        "            return True\n",
        "        if old_german in new_german or old_english in new_english:\n",
        "            return True\n",
        "    return False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "ZcIl8kLUiPCD"
      },
      "outputs": [],
      "source": [
        "# Get the latest propositions from the database.\n",
        "db = firestore.Client()\n",
        "database_propositions = []\n",
        "for proposition in db.collection('propositions').stream():\n",
        "    database_propositions.append(\n",
        "        ((proposition.get('number'), proposition.get('german')),\n",
        "         (proposition.get('number'), proposition.get('english'))))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xdRGZGk_PGlU"
      },
      "outputs": [],
      "source": [
        "# Collect a batch of propositions.\n",
        "num_completions = 3  # @param {type:\"integer\"}\n",
        "check_database = True  # @param {type:\"boolean\"}\n",
        "\n",
        "completions = complete(model=fine_tuned_model,\n",
        "                       prompt=prompt,\n",
        "                       prompt_separator=prompt_separator,\n",
        "                       num_completions=num_completions,\n",
        "                       max_tokens=max_tokens,\n",
        "                       top_p=top_p,\n",
        "                       stop_sequence=stop_sequence,\n",
        "                       presence_penalty=presence_penalty,\n",
        "                       frequency_penalty=frequency_penalty)\n",
        "\n",
        "new_propositions = []\n",
        "for choice in completions.choices:\n",
        "    if choice.finish_reason != 'stop':\n",
        "        # Incomplete proposition.\n",
        "        continue\n",
        "\n",
        "    try:\n",
        "        german_content, english_content = choice.text[1:].split(\n",
        "            language_separator)\n",
        "    except ValueError:\n",
        "        # Malformed proposition.\n",
        "        continue\n",
        "\n",
        "    if plagiarism(new_german=german_content,\n",
        "                  new_english=english_content,\n",
        "                  old_propositions=propositions):\n",
        "        # Proposition already exists in the original.\n",
        "        continue\n",
        "\n",
        "    if check_database and plagiarism(new_german=german_content,\n",
        "                                     new_english=english_content,\n",
        "                                     old_propositions=database_propositions):\n",
        "        # Proposition already exists in the database.\n",
        "        continue\n",
        "\n",
        "    if plagiarism(new_german=german_content,\n",
        "                  new_english=english_content,\n",
        "                  old_propositions=new_propositions):\n",
        "        # Proposition already exists in the current set.\n",
        "        continue\n",
        "\n",
        "    number = prompt\n",
        "\n",
        "    print(f'{number} {german_content}')\n",
        "    print(f'{number} {english_content}')\n",
        "    print()\n",
        "\n",
        "    new_propositions.append((\n",
        "        (number, german_content),\n",
        "        (number, english_content)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "EcXvNQv8tWKG"
      },
      "outputs": [],
      "source": [
        "def generate_preview(id):\n",
        "    # Configure a headless Chrome browser.\n",
        "    chrome_options = webdriver.chrome.options.Options()\n",
        "    chrome_options.add_argument('headless')\n",
        "    chrome_options.add_argument('no-sandbox')\n",
        "    chrome_options.add_argument('lang=en')\n",
        "    chrome_options.add_argument('window-size=1280x720')\n",
        "    chrome_options.add_argument('force-device-scale-factor=1')\n",
        "    chromedriver_service = webdriver.chrome.service.Service('chromedriver')\n",
        "\n",
        "    # Render the preview page and take a screenshot.\n",
        "    with webdriver.Chrome(service=chromedriver_service,\n",
        "                          options=chrome_options) as driver:\n",
        "        # TODO: Promote version and update URL.\n",
        "        driver.get(f'https://wittgenstein.app/preview/{id}.html')\n",
        "        driver.implicitly_wait(1)\n",
        "        screenshot = driver.get_screenshot_as_png()\n",
        "\n",
        "    # Upload the preview image to Google Cloud Storage.\n",
        "    storage_client = storage.Client()\n",
        "    previews_bucket = storage_client.bucket(f'{google_cloud_project}-previews')\n",
        "    preview_blob_name = f'{id}.png'\n",
        "    preview_blob = previews_bucket.blob(preview_blob_name)\n",
        "    preview_blob.upload_from_string(screenshot, content_type='image/png')\n",
        "    preview_blob.make_public()\n",
        "\n",
        "    return preview_blob.public_url"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WBC9P0GKdKSi"
      },
      "outputs": [],
      "source": [
        "# Add the new propositions to the database.\n",
        "propositions_ref = db.collection('propositions')\n",
        "metadata_ref = db.collection('metadata').document('propositions')\n",
        "for german_proposition, english_proposition in new_propositions:\n",
        "    german_number, german_content = german_proposition\n",
        "    english_number, english_content = english_proposition\n",
        "    assert german_number == english_number\n",
        "\n",
        "    @firestore.transactional\n",
        "    def insert_proposition(transaction, proposition_ref, metadata_ref):\n",
        "        # Use the current total number of propositions as the new index.\n",
        "        metadata = metadata_ref.get(transaction=transaction)\n",
        "        index = metadata.get('total')\n",
        "\n",
        "        # Insert the new proposition.\n",
        "        data = {\n",
        "            'number': german_number,\n",
        "            'german': german_content,\n",
        "            'english': english_content,\n",
        "            'model': completions.model,\n",
        "            'top_p': top_p,\n",
        "            'presence_penalty': presence_penalty,\n",
        "            'frequency_penalty': frequency_penalty,\n",
        "            'timestamp': datetime.now(),\n",
        "            'prompt': prompt,\n",
        "            'completion_id': completions.id,\n",
        "            'index': index\n",
        "        }\n",
        "        transaction.set(proposition_ref, data)\n",
        "\n",
        "        # Increment the total number of propositions.\n",
        "        transaction.update(metadata_ref, {'total': firestore.Increment(1)})\n",
        "\n",
        "        return index\n",
        "\n",
        "    # Update the database with an atomic transaction.\n",
        "    transaction = db.transaction()\n",
        "    proposition_ref = propositions_ref.document()\n",
        "    index = insert_proposition(transaction, proposition_ref, metadata_ref)\n",
        "\n",
        "    # Generate the preview image.\n",
        "    preview_url = generate_preview(proposition_ref.id)\n",
        "\n",
        "    print(f'{index} https://wittgenstein.app/{proposition_ref.id} {preview_url}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KjXkDczVNQqF"
      },
      "source": [
        "# Delete"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "NgKaK-bKJZil"
      },
      "outputs": [],
      "source": [
        "id = ''  # @param {type:\"string\"}\n",
        "\n",
        "@firestore.transactional\n",
        "def remove_proposition(transaction, propositions_ref, metadata_ref, id):\n",
        "    proposition_ref = propositions_ref.document(id)\n",
        "    if not proposition_ref.get(transaction=transaction).exists:\n",
        "        print(f'ID not found: {id}')\n",
        "        return\n",
        "\n",
        "    # Delete the proposition.\n",
        "    transaction.delete(proposition_ref)\n",
        "\n",
        "    # Assign all propositions a monotonically increasing index.\n",
        "    index = 0\n",
        "    for proposition in propositions_ref.stream():\n",
        "        if proposition.id == id:\n",
        "            continue\n",
        "\n",
        "        proposition_ref = propositions_ref.document(proposition.id)\n",
        "        transaction.update(proposition_ref, {'index': index})\n",
        "        index += 1\n",
        "\n",
        "    # Update the total number in the metadata.\n",
        "    transaction.update(metadata_ref, {'total': index})\n",
        "\n",
        "\n",
        "transaction = db.transaction()\n",
        "propositions_ref = db.collection('propositions')\n",
        "metadata_ref = db.collection('metadata').document('propositions')\n",
        "remove_proposition(transaction, propositions_ref, metadata_ref, id)\n",
        "\n",
        "# Delete the preview image\n",
        "storage_client = storage.Client()\n",
        "previews_bucket = storage_client.bucket('previews.wittgenstein.app')\n",
        "preview_blob_name = f'{id}.png'\n",
        "preview_blob = previews_bucket.blob(preview_blob_name)\n",
        "preview_blob.delete()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Wittgenstein 2022",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
