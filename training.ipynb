{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mvm9KLxAiYqi"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uTKPzu28dHvF"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade pylatexenc anytree openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "QNBY5xlIc3F7"
      },
      "outputs": [],
      "source": [
        "import anytree\n",
        "from datetime import datetime\n",
        "import json\n",
        "import openai\n",
        "from pylatexenc import latexwalker\n",
        "from pylatexenc.latexwalker import LatexEnvironmentNode\n",
        "from pylatexenc.latexwalker import LatexGroupNode\n",
        "from pylatexenc.latexwalker import LatexMacroNode\n",
        "from pylatexenc.latexwalker import LatexWalker\n",
        "from pylatexenc import latex2text\n",
        "from pylatexenc.latex2text import EnvironmentTextSpec\n",
        "from pylatexenc.latex2text import fmt_matrix_environment_node\n",
        "from pylatexenc.latex2text import LatexNodes2Text\n",
        "from pylatexenc.latex2text import MacroTextSpec\n",
        "from pylatexenc.latex2text import SpecialsTextSpec\n",
        "from pylatexenc.macrospec import EnvironmentSpec\n",
        "from pylatexenc.macrospec import MacroSpec\n",
        "from pylatexenc.macrospec import MacroStandardArgsParser\n",
        "from pylatexenc.macrospec import SpecialsSpec\n",
        "import re\n",
        "import requests\n",
        "import subprocess"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-F6becSrvS9Y"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/maxbbraun/wittgenstein.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bKGZ7PlrxGIx"
      },
      "source": [
        "# Data Preparation\n",
        "\n",
        "Source: https://www.gutenberg.org/ebooks/5740"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "h3w5NI-zjyHC"
      },
      "outputs": [],
      "source": [
        "# Load the (corrected) LaTeX version of the Tractatus into memory.\n",
        "with open('wittgenstein/tractatus.tex') as f:\n",
        "  tractatus_latex = f.read()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "07YK6FQpcjYD"
      },
      "outputs": [],
      "source": [
        "# Define parsing rules for turning LaTeX into Unicode text with minimal HTML.\n",
        "def init_pylatexenc(translate_to_english, include_footnotes=False):\n",
        "  walker_context = latexwalker.get_default_latex_context_db()\n",
        "  walker_context.add_context_category(\n",
        "      'tractatus',\n",
        "      prepend=True,\n",
        "      macros=[\n",
        "          MacroSpec('binom', '{{'),\n",
        "          MacroSpec('BookTitle', '{'),\n",
        "          MacroSpec('discretionary', '{{{'),\n",
        "          MacroSpec('DPtypo', '{{'),\n",
        "          MacroSpec('emph', '{'),\n",
        "          MacroSpec('Emph', '{'),\n",
        "          MacroSpec('EmphPart', '{'),\n",
        "          MacroSpec('enlargethispage', '{'),\n",
        "          MacroSpec('glq', '{'),\n",
        "          MacroSpec('glqq', '{'),\n",
        "          MacroSpec('grq', '{'),\n",
        "          MacroSpec('grqq', '{'),\n",
        "          MacroSpec('hspace', '{'),\n",
        "          MacroSpec('Illustration', '[{'),\n",
        "          MacroSpec('mbox', '{'),\n",
        "          MacroSpec('Not', '{'),\n",
        "          MacroSpec('overline', '{'),\n",
        "          MacroSpec('phantom', '{'),\n",
        "          MacroSpec('PropERef', '{'),\n",
        "          MacroSpec('PropGRef', '{'),\n",
        "          MacroSpec('PropositionE', '{{'),\n",
        "          MacroSpec('PropositionG', '{{'),\n",
        "          MacroSpec('raisebox', '{[[{'),\n",
        "          MacroSpec('smash', '[[{'),\n",
        "          MacroSpec('text', '{'),\n",
        "          MacroSpec('textit', '{'),\n",
        "          MacroSpec('vspace', '{')],\n",
        "      environments=[\n",
        "          EnvironmentSpec('array', '[{', is_math_mode=True),\n",
        "          EnvironmentSpec('split', '', is_math_mode=True),\n",
        "          EnvironmentSpec('tabular', '[{')],\n",
        "      specials=[\n",
        "          SpecialsSpec('`'),\n",
        "          SpecialsSpec(\"'\"),\n",
        "          SpecialsSpec('``'),\n",
        "          SpecialsSpec(\"''\"),\n",
        "          SpecialsSpec('&'),\n",
        "          SpecialsSpec('^', args_parser=MacroStandardArgsParser('{')),\n",
        "          SpecialsSpec('_', args_parser=MacroStandardArgsParser('{'))])\n",
        "  latex_walker = LatexWalker(tractatus_latex, latex_context=walker_context)\n",
        "\n",
        "  if translate_to_english:\n",
        "    footnote_pattern = r' (Footnote: %(2)s)' if include_footnotes else ''\n",
        "    binomial_pattern = r'(%(1)s choose %(2)s)'\n",
        "    single_open_quote = '‘'\n",
        "    single_close_quote = '’'\n",
        "    double_open_quote = '“'\n",
        "    double_close_quote = '”'\n",
        "    illustration_placeholder = '[Figure]'\n",
        "  else:\n",
        "    footnote_pattern = r' (Fußnote: %(2)s)' if include_footnotes else ''\n",
        "    binomial_pattern = r'(%(1)s über %(2)s)'\n",
        "    single_open_quote = '‚'\n",
        "    single_close_quote = '‘'\n",
        "    double_open_quote = '„'\n",
        "    double_close_quote = '“'\n",
        "    illustration_placeholder = '[Abbildung]'\n",
        "\n",
        "  nodes2text_context = latex2text.get_default_latex_context_db()\n",
        "  nodes2text_context.add_context_category(\n",
        "      'tractatus',\n",
        "      prepend=True,\n",
        "      macros=[\n",
        "          MacroTextSpec('-', discard=True),\n",
        "          MacroTextSpec('AllowBreak', discard=True),\n",
        "          MacroTextSpec('BarOp', simplify_repl=' | '),\n",
        "          MacroTextSpec('binom', simplify_repl=binomial_pattern),\n",
        "          MacroTextSpec('BookTitle', simplify_repl=r'%s'),\n",
        "          MacroTextSpec('dasHeiszt', simplify_repl='d. h.'),\n",
        "          MacroTextSpec('discretionary', simplify_repl=r'%(3)s'),\n",
        "          MacroTextSpec('DittoInWords', simplify_repl='„'),\n",
        "          MacroTextSpec('DittoInWorten', simplify_repl='„'),\n",
        "          MacroTextSpec('DotOp', simplify_repl=' . '),\n",
        "          MacroTextSpec('DPtypo', simplify_repl=r'%(2)s'),\n",
        "          MacroTextSpec('emph', simplify_repl=r'<em>%s</em>'),\n",
        "          MacroTextSpec('Emph', simplify_repl=r'<em>%s</em>'),\n",
        "          MacroTextSpec('EmphPart', simplify_repl=r'<em>%s</em>'),\n",
        "          MacroTextSpec('False', simplify_repl='F'),\n",
        "          MacroTextSpec('enlargethispage', discard=True),\n",
        "          MacroTextSpec('exempliGratia', simplify_repl='e.g.'),\n",
        "          MacroTextSpec('ExempliGratia', simplify_repl='E.g.'),\n",
        "          MacroTextSpec('fivedots', simplify_repl='.....'),\n",
        "          MacroTextSpec('footnote', simplify_repl=footnote_pattern),\n",
        "          MacroTextSpec('fourdots', simplify_repl='....'),\n",
        "          MacroTextSpec('glq', simplify_repl=single_open_quote),\n",
        "          MacroTextSpec('glqq', simplify_repl=double_open_quote),\n",
        "          MacroTextSpec('grq', simplify_repl=single_close_quote),\n",
        "          MacroTextSpec('grqq', simplify_repl=double_close_quote),\n",
        "          MacroTextSpec('hline', simplify_repl='; '),\n",
        "          MacroTextSpec('hspace', discard=True),\n",
        "          MacroTextSpec('idEst', simplify_repl='i.e.'),\n",
        "          MacroTextSpec('IdEst', simplify_repl='I.e.'),\n",
        "          MacroTextSpec('Illustration',\n",
        "                        simplify_repl=illustration_placeholder),\n",
        "          MacroTextSpec('Implies', simplify_repl='⊃'),\n",
        "          MacroTextSpec('lor', simplify_repl='v'),\n",
        "          MacroTextSpec('mbox', simplify_repl='%s'),\n",
        "          MacroTextSpec('Not', simplify_repl='~%s'),\n",
        "          MacroTextSpec('overline', simplify_repl='%s\\u0305'),\n",
        "          MacroTextSpec('phantom', discard=True),\n",
        "          MacroTextSpec('PropERef', simplify_repl=r'%s'),\n",
        "          MacroTextSpec('PropGRef', simplify_repl=r'%s'),\n",
        "          MacroTextSpec('raisebox', simplify_repl=r'%(4)s'),\n",
        "          MacroTextSpec('smash', simplify_repl=r'%(3)s'),\n",
        "          MacroTextSpec('stretchyspace', discard=True),\n",
        "          MacroTextSpec('text', simplify_repl=r'%s'),\n",
        "          MacroTextSpec('textit', simplify_repl=r'<i>%s<i>'),\n",
        "          MacroTextSpec('undAndere', simplify_repl='u. a.'),\n",
        "          MacroTextSpec('undSoFort', simplify_repl='u. s. f.'),\n",
        "          MacroTextSpec('UndSoWeiter', simplify_repl='U. s. w.'),\n",
        "          MacroTextSpec('verystretchyspace', discard=True),\n",
        "          MacroTextSpec('vspace', discard=True),\n",
        "          MacroTextSpec('Wahr', simplify_repl='W'),\n",
        "          MacroTextSpec('zumBeispiel', simplify_repl='z. B.'),\n",
        "          MacroTextSpec('ZumBeispiel', simplify_repl='Z. B.')],\n",
        "      environments=[\n",
        "          EnvironmentTextSpec('array',\n",
        "                              simplify_repl=fmt_matrix_environment_node),\n",
        "          EnvironmentTextSpec('split',\n",
        "                              simplify_repl=fmt_matrix_environment_node),\n",
        "          EnvironmentTextSpec('tabular',\n",
        "                              simplify_repl=fmt_matrix_environment_node)],\n",
        "      specials=[\n",
        "          SpecialsTextSpec('`', single_open_quote),\n",
        "          SpecialsTextSpec(\"'\", single_close_quote),\n",
        "          SpecialsTextSpec('``', double_open_quote),\n",
        "          SpecialsTextSpec(\"''\", double_close_quote),\n",
        "          SpecialsTextSpec('&', '|'),\n",
        "          SpecialsTextSpec('^', simplify_repl='<sup>%s</sup>'),\n",
        "          SpecialsTextSpec('_', simplify_repl='<sub>%s</sub>')])\n",
        "  nodes2text = LatexNodes2Text(latex_context=nodes2text_context,\n",
        "                               math_mode='text',\n",
        "                               keep_braced_groups=False)\n",
        "\n",
        "  return latex_walker, nodes2text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "Shcznprpc-Ya"
      },
      "outputs": [],
      "source": [
        "# Find the propositions in the structured text.\n",
        "def gather_propositions(translate_to_english, nodes=None, latex_walker=None,\n",
        "                        nodes2text=None):\n",
        "  if not nodes:\n",
        "    latex_walker, nodes2text = init_pylatexenc(\n",
        "        translate_to_english=translate_to_english)\n",
        "    nodes, _, _ = latex_walker.get_latex_nodes()\n",
        "  assert latex_walker\n",
        "  assert nodes2text\n",
        "\n",
        "  # Pick the proposition macro based on the selected language.\n",
        "  if translate_to_english:\n",
        "    proposition_macro = 'PropositionE'\n",
        "  else:\n",
        "    proposition_macro = 'PropositionG'\n",
        "\n",
        "  # Walk the nodes tree recursively and extract all propositions.\n",
        "  propositions = []\n",
        "  for node in nodes:\n",
        "    if node.isNodeType(LatexGroupNode) or node.isNodeType(LatexEnvironmentNode):\n",
        "      # Recurse into groups of nodes.\n",
        "      child_nodes = node.nodelist\n",
        "      if child_nodes:\n",
        "        child_propositions = gather_propositions(\n",
        "            translate_to_english=translate_to_english, nodes=child_nodes,\n",
        "            latex_walker=latex_walker, nodes2text=nodes2text)\n",
        "        propositions.extend(child_propositions)\n",
        "    elif (node.isNodeType(LatexMacroNode) and\n",
        "          node.macroname == proposition_macro):\n",
        "      # Expect the proposition's number and content as the node arguments.\n",
        "      proposition_nodes = node.nodeargd.argnlist\n",
        "      assert len(proposition_nodes) == 2\n",
        "      number_node = proposition_nodes[0]\n",
        "      content_node = proposition_nodes[1]\n",
        "\n",
        "      # Convert the number and content to text.\n",
        "      number = nodes2text.node_to_text(number_node)\n",
        "      content = nodes2text.node_to_text(content_node)\n",
        "\n",
        "      # Remove any repeated and trailing whitespace.\n",
        "      content = re.sub(r'\\s+', ' ', content).strip()\n",
        "\n",
        "      proposition = (number, content)\n",
        "      propositions.append(proposition)\n",
        "\n",
        "  return propositions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 215,
      "metadata": {
        "id": "EmDDjCmOoQAF"
      },
      "outputs": [],
      "source": [
        "# Extract the propositions for both languages.\n",
        "german_propositions = gather_propositions(translate_to_english=False)\n",
        "english_propositions = gather_propositions(translate_to_english=True)\n",
        "assert len(german_propositions) == len(english_propositions)\n",
        "propositions = list(zip(german_propositions, english_propositions))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XZVKk9tv3GGG"
      },
      "outputs": [],
      "source": [
        "# Put the propositions into a tree structure.\n",
        "propositions_tree = anytree.AnyNode(number='')\n",
        "for german_proposition, english_proposition in propositions:\n",
        "  number, german_content = german_proposition\n",
        "  english_number, english_content = english_proposition\n",
        "  assert number == english_number\n",
        "\n",
        "  # Determine the number of the parent.\n",
        "  parent_number = number[:-1]\n",
        "  while parent_number.endswith('0'):\n",
        "    parent_number = parent_number[:-1]\n",
        "  if parent_number.endswith('.'):\n",
        "    parent_number = parent_number[:-1]\n",
        "  def parent_number_filter(node):\n",
        "    return node.number == parent_number\n",
        "  parent_node = anytree.search.find(propositions_tree,\n",
        "                                    filter_=parent_number_filter)\n",
        "\n",
        "  # Create the new node and attach it to the parent.\n",
        "  anytree.AnyNode(number=number, parent=parent_node,\n",
        "                  german_content=german_content,\n",
        "                  english_content=english_content)\n",
        "\n",
        "print(anytree.RenderTree(propositions_tree))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZcL0AznClUoA"
      },
      "source": [
        "# Data Inspection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "pB942k2kCYdu"
      },
      "outputs": [],
      "source": [
        "def proposition_importance(proposition_number):\n",
        "  # The importance of the proposition, with 0 being the most important.\n",
        "  number_match = re.search(r'(\\d+)(\\.(\\d+))?', proposition_number)\n",
        "  importance = len(number_match.group(3) or '')\n",
        "\n",
        "  return importance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "V9oU3FTXNhHP"
      },
      "outputs": [],
      "source": [
        "def proposition_html(number, german_content, english_content):\n",
        "  html = ''\n",
        "\n",
        "  # Hide all but 0 importance propositions by default.\n",
        "  if proposition_importance(number) > 0:\n",
        "    html += '<tr class=\"expandable\" style=\"display: none;\">\\n'\n",
        "  else:\n",
        "    html += '<tr>\\n'\n",
        "\n",
        "  # See frontend/templates/index.html for CSS.\n",
        "  html += '  <td class=\"english number mobile\">%s</td>\\n' % number\n",
        "  html += '  <td class=\"english proposition\">%s</td>\\n' % english_content\n",
        "  html += '  <td class=\"german number nomobile\">%s</td>\\n' % number\n",
        "  html += '  <td class=\"german proposition nomobile\">%s</td>\\n' % german_content\n",
        "  html += '</tr>'\n",
        "\n",
        "  return html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5bTXYpaTXWsN"
      },
      "outputs": [],
      "source": [
        "importance_limit = 5  # @param {type:\"slider\", min:0, max:5, step:1}\n",
        "proposition_prefix = ''  # @param{type:\"string\"}\n",
        "as_html = True  # @param {type:\"boolean\"}\n",
        "reverse = True  # @param {type:\"boolean\"}\n",
        "\n",
        "if reverse:\n",
        "  ordered = reversed(propositions)\n",
        "else:\n",
        "  ordered = propositions\n",
        "\n",
        "for german_proposition, english_proposition in ordered:\n",
        "  number, german_content = german_proposition\n",
        "  english_number, english_content = english_proposition\n",
        "  assert number == english_number\n",
        "\n",
        "  if not number.startswith(proposition_prefix):\n",
        "    continue\n",
        "\n",
        "  importance = proposition_importance(number)\n",
        "  if importance > importance_limit:\n",
        "    continue\n",
        "\n",
        "  if as_html:\n",
        "    print(proposition_html(number, german_content, english_content))\n",
        "  else:\n",
        "    print('%s %s' % (number, german_content))\n",
        "    print('%s %s' % (number, english_content))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6jbPIStXw_l8"
      },
      "source": [
        "# Training\n",
        "\n",
        "Documentation: https://beta.openai.com/docs/guides/fine-tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XyTY9jt88yOg"
      },
      "outputs": [],
      "source": [
        "openai_api_key = ''  # @param {type:\"string\"}\n",
        "%env OPENAI_API_KEY=$openai_api_key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "RcYFHdyhd23H"
      },
      "outputs": [],
      "source": [
        "prompt_separator = ' ->'  # @param{type:\"string\"}\n",
        "language_separator = '==='  # @param{type:\"string\"}\n",
        "proposition_separator = '\\n'  # @param{type:\"string\"}\n",
        "stop_sequence = '###'  # @param{type:\"string\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "qWCDzP9YwfIm"
      },
      "outputs": [],
      "source": [
        "training_filename = 'tractatus-%d.jsonl' % datetime.now().timestamp()\n",
        "\n",
        "with open(training_filename, 'w', encoding='utf-8') as training_file:\n",
        "  for node in anytree.PreOrderIter(propositions_tree,\n",
        "                                   filter_=lambda node: node.number):\n",
        "    prompt = node.number\n",
        "    completion = ' %s%s%s' % (node.german_content,\n",
        "                              language_separator,\n",
        "                              node.english_content)\n",
        "\n",
        "    prompt += prompt_separator\n",
        "    completion += stop_sequence\n",
        "\n",
        "    data = {\n",
        "        'prompt': prompt,\n",
        "        'completion': completion\n",
        "    }\n",
        "    json_line = '%s\\n' % json.dumps(data, ensure_ascii=False)\n",
        "    training_file.write(json_line)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7wjD6j14vTTQ"
      },
      "outputs": [],
      "source": [
        "!openai tools fine_tunes.prepare_data --file $training_filename"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yzsLBnAhv_ju"
      },
      "outputs": [],
      "source": [
        "model = 'davinci'  # @param [\"ada\", \"babbage\", \"curie\", \"davinci\"]\n",
        "batch_size = 1  # @param{type:\"integer\"}\n",
        "n_epochs = 4  # @param{type:\"integer\"}\n",
        "learning_rate_multiplier = 0.02  # @param{type:\"number\"}\n",
        "prompt_loss_weight = 0.1  # @param{type:\"number\"}\n",
        "\n",
        "!openai api fine_tunes.create --training_file $training_filename --model $model --batch_size $batch_size --n_epochs $n_epochs --learning_rate_multiplier $learning_rate_multiplier --prompt_loss_weight $prompt_loss_weight"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zA1SgdNoxOzf"
      },
      "source": [
        "# Inference\n",
        "\n",
        "Documentation: https://beta.openai.com/docs/api-reference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 202,
      "metadata": {
        "id": "0lAeNjBMi5aa"
      },
      "outputs": [],
      "source": [
        "def complete(model, prompt, prompt_separator, num_completions, max_tokens,\n",
        "             top_p, stop_sequence, presence_penalty, frequency_penalty):\n",
        "  return openai.Completion.create(\n",
        "      model=model,\n",
        "      prompt='%s%s' % (prompt, prompt_separator),\n",
        "      n=num_completions,\n",
        "      max_tokens=max_tokens,\n",
        "      top_p=top_p,\n",
        "      stop=stop_sequence,\n",
        "      presence_penalty=presence_penalty,\n",
        "      frequency_penalty=frequency_penalty)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 314,
      "metadata": {
        "id": "k7oHA-aL_qg2"
      },
      "outputs": [],
      "source": [
        "openai.organization = \"\"  # @param {type:\"string\"}\n",
        "openai.api_key = openai_api_key\n",
        "fine_tuned_model = ''  # @param {type:\"string\"}\n",
        "prompt = '8'  # @param {type:\"string\"}\n",
        "max_tokens = 1024  # @param {type:\"integer\"}\n",
        "top_p = 0.7  # @param {type:\"slider\", min:0, max:1, step:0.1}\n",
        "presence_penalty = 1  # @param {type:\"slider\", min:-2.0, max:2.0, step:0.1}\n",
        "frequency_penalty = 1  # @param {type:\"slider\", min:-2.0, max:2.0, step:0.1}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MNNTbcamLOWO"
      },
      "outputs": [],
      "source": [
        "# Sample a single proposition.\n",
        "completions = complete(model=fine_tuned_model,\n",
        "                       prompt=prompt,\n",
        "                       prompt_separator=prompt_separator,\n",
        "                       num_completions=1,\n",
        "                       max_tokens=max_tokens,\n",
        "                       top_p=top_p,\n",
        "                       stop_sequence=stop_sequence,\n",
        "                       presence_penalty=presence_penalty,\n",
        "                       frequency_penalty=frequency_penalty)\n",
        "proposition = completions.choices[0].text[1:]\n",
        "number = prompt\n",
        "german_content, english_content = proposition.split(language_separator)\n",
        "\n",
        "print('%s %s' % (number, german_content))\n",
        "print('%s %s' % (number, english_content))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 316,
      "metadata": {
        "id": "Roe2rbd6rYxn"
      },
      "outputs": [],
      "source": [
        "def plagiarism(new_german, new_english, old_propositions):\n",
        "  for (_, old_german), (_, old_english) in old_propositions:\n",
        "    # Any partial match is considered plagiarism.\n",
        "    if new_german in old_german or new_english in old_english:\n",
        "      return True\n",
        "  return False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xdRGZGk_PGlU"
      },
      "outputs": [],
      "source": [
        "# Collect many propositions.\n",
        "num_completions = 12  # @param {type:\"integer\"}\n",
        "\n",
        "completions = complete(model=fine_tuned_model,\n",
        "                       prompt=prompt,\n",
        "                       prompt_separator=prompt_separator,\n",
        "                       num_completions=num_completions,\n",
        "                       max_tokens=max_tokens,\n",
        "                       top_p=top_p,\n",
        "                       stop_sequence=stop_sequence,\n",
        "                       presence_penalty=presence_penalty,\n",
        "                       frequency_penalty=frequency_penalty)\n",
        "\n",
        "new_propositions = []\n",
        "for choice in completions.choices:\n",
        "  if choice.finish_reason != 'stop':\n",
        "    # Incomplete proposition.\n",
        "    continue\n",
        "\n",
        "  german_content, english_content = choice.text[1:].split(language_separator)\n",
        "\n",
        "  if plagiarism(new_german=german_content,\n",
        "                new_english=english_content,\n",
        "                old_propositions=propositions):\n",
        "    # Proposition already exists in the original.\n",
        "    continue\n",
        "\n",
        "  if plagiarism(new_german=german_content,\n",
        "                new_english=english_content,\n",
        "                old_propositions=new_propositions):\n",
        "    # Proposition already exists in the current set.\n",
        "    continue\n",
        "\n",
        "  number = prompt\n",
        "\n",
        "  new_propositions.append((\n",
        "      (number, german_content),\n",
        "      (number, english_content)))\n",
        "\n",
        "print('%d new propositions' % len(new_propositions))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 318,
      "metadata": {
        "id": "H2n_9F-4wnU0"
      },
      "outputs": [],
      "source": [
        "insert_query = \"\"\"INSERT\n",
        "  tractatus.propositions (id,\n",
        "    number,\n",
        "    german,\n",
        "    english,\n",
        "    model,\n",
        "    prompt,\n",
        "    top_p,\n",
        "    presence_penalty,\n",
        "    frequency_penalty,\n",
        "    completion_id,\n",
        "    timestamp)\n",
        "\"\"\"\n",
        "\n",
        "insert_values = []\n",
        "for german_proposition, english_proposition in new_propositions:\n",
        "  german_number, german_content = german_proposition\n",
        "  english_number, english_content = english_proposition\n",
        "  assert german_number == english_number\n",
        "\n",
        "  insert_value = (\n",
        "      \"REGEXP_EXTRACT(GENERATE_UUID(), r'^[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-([0-9a-f]{12})$')\",\n",
        "      \"'%s'\" % german_number,\n",
        "      \"'%s'\" % german_content,\n",
        "      \"'%s'\" % english_content,\n",
        "      \"'%s'\" % completions.model,\n",
        "      \"'%s'\" % prompt,\n",
        "      \"%s\" % top_p,\n",
        "      \"%s\" % presence_penalty,\n",
        "      \"%s\" % frequency_penalty,\n",
        "      \"'%s'\" % completions.id,\n",
        "      'CURRENT_TIMESTAMP()')\n",
        "  insert_values.append('  (%s)' % ', '.join(insert_value))\n",
        "\n",
        "insert_query += 'VALUES\\n%s' % ',\\n'.join(insert_values)\n",
        "\n",
        "print(insert_query)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Wittgenstein 2022",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
